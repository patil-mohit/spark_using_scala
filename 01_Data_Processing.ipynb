{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SPARK SESSION:\n",
    "\n",
    "Open spark shell using below command:\n",
    "\n",
    "[mohitpatil@gw02 ~]$ spark2-shell \\\n",
    "> --master yarn\n",
    "\n",
    "To read the data :\n",
    "\n",
    "COPY  : CNTRL + FN + INSERT\n",
    "PASTE : SHIFT + FN + INSERT \n",
    "\n",
    "[mohitpatil@gw02 ~]$ hdfs dfs -ls /public/retail_db/orders\n",
    "Found 1 items\n",
    "-rw-r--r--   3 hdfs hdfs    2999944 2016-12-19 03:52 /public/retail_db/orders/part-00000\n",
    "[mohitpatil@gw02 ~]$ hdfs dfs -cat /public/retail_db/orders/part-00000|more\n",
    "\n",
    "You can exit through $CAT commad by pressing 'q'\n",
    "\n",
    "You can check the last 10 records by below command:\n",
    "\n",
    "[mohitpatil@gw02 ~]$ hdfs dfs -tail /public/retail_db/orders/part-00000\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "***IMPORTANT TRICK***\n",
    "use HDFS DFS commands in saprk shell by using following way:\n",
    "\n",
    "scala> import sys.process._\n",
    "import sys.process._\n",
    "\n",
    "\n",
    "scala> \"hdfs dfs <command> \" !\n",
    "\n",
    "scala> \"hdfs dfs -ls /public/retail_db/orders/\" !\n",
    "warning: there was one feature warning; re-run with -feature for details\n",
    "Found 1 items\n",
    "-rw-r--r--   3 hdfs hdfs    2999944 2016-12-19 03:52 /public/retail_db/orders/part-00000\n",
    "res11: Int = 0\n",
    "\n",
    "\n",
    "scala> \"hdfs dfs -tail /public/retail_db/orders/part-00000\" !\n",
    "warning: there was one feature warning; re-run with -feature for details\n",
    "014-06-12 00:00:00.0,4229,PENDING\n",
    "68861,2014-06-13 00:00:00.0,3031,PENDING_PAYMENT\n",
    "68862,2014-06-15 00:00:00.0,7326,PROCESSING\n",
    "68863,2014-06-16 00:00:00.0,3361,CLOSED\n",
    "68864,2014-06-18 00:00:00.0,9634,ON_HOLD\n",
    "68865,2014-06-19 00:00:00.0,4567,SUSPECTED_FRAUD\n",
    "68866,2014-06-20 00:00:00.0,3890,PENDING_PAYMENT\n",
    "68867,2014-06-23 00:00:00.0,869,CANCELED\n",
    "68868,2014-06-24 00:00:00.0,10184,PENDING\n",
    "68869,2014-06-25 00:00:00.0,7456,PROCESSING\n",
    "68870,2014-06-26 00:00:00.0,3343,COMPLETE\n",
    "68871,2014-06-28 00:00:00.0,4960,PENDING\n",
    "68872,2014-06-29 00:00:00.0,3354,COMPLETE\n",
    "68873,2014-06-30 00:00:00.0,4545,PENDING\n",
    "68874,2014-07-03 00:00:00.0,1601,COMPLETE\n",
    "68875,2014-07-04 00:00:00.0,10637,ON_HOLD\n",
    "68876,2014-07-06 00:00:00.0,4124,COMPLETE\n",
    "68877,2014-07-07 00:00:00.0,9692,ON_HOLD\n",
    "68878,2014-07-08 00:00:00.0,6753,COMPLETE\n",
    "68879,2014-07-09 00:00:00.0,778,COMPLETE\n",
    "68880,2014-07-13 00:00:00.0,1117,COMPLETE\n",
    "68881,2014-07-19 00:00:00.0,2518,PENDING_PAYMENT\n",
    "68882,2014-07-22 00:00:00.0,10000,ON_HOLD\n",
    "68883,2014-07-23 00:00:00.0,5533,COMPLETE\n",
    "res12: Int = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading source file:\n",
    "\n",
    "scala> val orders = spark.read.csv(\"/public/retail_db/orders\")\n",
    "orders: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 2 more fields]\n",
    "\n",
    "\n",
    "Reading JSON data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS OVERVIEW\n",
    "\n",
    "## Important functions broadly categorized as below:\n",
    "1. String Manipulation Function\n",
    "2. Date Manipulation Function\n",
    "3. Numeric Function\n",
    "4. Aggregate Function\n",
    "\n",
    "We cannot use the DF.select() function to manipulate strings.\n",
    "\n",
    "If we want to apply function on it then it should be of COLUMN type.\n",
    "\n",
    "We have to convert column names to col type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
